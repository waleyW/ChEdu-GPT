{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. c纯sql做数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答案: Self absorption occurs at higher concentrations when the light that is emitted by an excited atom gets absorbed by the sample, instead of the light thats coming from the light source. This makes the sample look less concentrated than it is.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# 读取CSV文件\n",
    "csv_file_path = r'/home/ubuntu/mnt2/wxy/Ako_GPT/data/exam_entry_answer.csv'  # 替换为您的CSV文件路径\n",
    "data = pd.read_csv(csv_file_path,encoding='ISO-8859-1')\n",
    "\n",
    "\n",
    "conn = sqlite3.connect('questions.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS questions (\n",
    "    entry TEXT PRIMARY KEY,\n",
    "    answer TEXT\n",
    ")\n",
    "''')\n",
    "\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    cursor.execute('INSERT OR IGNORE INTO questions (entry, answer) VALUES (?, ?)', (row['entry'], row['answer']))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "def get_answer(entry_id):\n",
    "    cursor.execute(\"SELECT answer FROM questions WHERE entry=?\", (entry_id,))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return \"Nope\"\n",
    "\n",
    "# 示例使用\n",
    "entry_id = input(\"Please enter the question ID: \")\n",
    "answer = get_answer(entry_id)\n",
    "print(f\"answer: {answer}\")\n",
    "\n",
    "# 关闭数据库连接\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 RAG+LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "conn = sqlite3.connect('questions.db')\n",
    "def get_answer(entry_id):\n",
    "    cursor.execute(\"SELECT answer FROM questions WHERE entry=?\", (entry_id,))\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# model\n",
    "tokenizer = AutoTokenizer.from_pretrained(r\"/home/ubuntu/mnt2/wxy/model/Mistral-7B-Instruct-v0.3\")  # 替换为实际模型名称\n",
    "model = AutoModelForCausalLM.from_pretrained(r\"/home/ubuntu/mnt2/wxy/model/Mistral-7B-Instruct-v0.3\")\n",
    "\n",
    "# 调用LLM处理组合输入的函数\n",
    "def send_to_llm(input_text):\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=2000)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# 处理用户输入并发送到LLM的函数\n",
    "def process_query(query):\n",
    "    # 从用户输入中提取题号\n",
    "    match = re.search(r'question ID is (\\w+)', query)\n",
    "    if match:\n",
    "        entry_id = match.group(1)\n",
    "        answer = get_answer(entry_id)\n",
    "        if answer:\n",
    "            combined_input = f\"Question ID: {entry_id}\\nRetrieved Answer: {answer}\\n\\nUser Query: {query}\"\n",
    "            response = send_to_llm(combined_input)\n",
    "            return response\n",
    "        else:\n",
    "            return \"The specified question number was not found. Please check whether the question number is correct.\"\n",
    "    else:\n",
    "        return \"No valid question number was found in the exam database.\"\n",
    "\n",
    "# example\n",
    "user_input = input(\"Please enter your query (for example: Question number is xxx, please help me solve this question):\")\n",
    "output = process_query(user_input)\n",
    "print(output)\n",
    "\n",
    "# close\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成考试信息的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Define lists for generating diverse data\n",
    "subjects = [\n",
    "    # Class series\n",
    "    \"Class1\", \"Class2\", \"Class3\", \"Class4\", \n",
    "    \"Class5\", \"Class6\", \"Class7\", \"Class8\", \n",
    "    \"Class9\", \"Class10\",\n",
    "\n",
    "    # Chem series\n",
    "    \"Chem1\", \"Chem2\", \"Chem3\", \"Chem4\", \n",
    "    \"Chem5\", \"Chem6\", \"Chem7\", \"Chem8\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "classrooms = [\n",
    "    \"A101\", \"B205\", \"C302\", \"D401\", \"E502\", \n",
    "    \"F203\", \"G104\", \"H306\", \"I405\", \"J201\",\n",
    "    \"K302\", \"L404\", \"M205\", \"N106\", \"O407\"\n",
    "]\n",
    "\n",
    "teachers = [\n",
    "    \"Dr. Smith\", \"Prof. Johnson\", \"Dr. Williams\", \n",
    "    \"Prof. Brown\", \"Dr. Miller\", \"Prof. Davis\", \n",
    "    \"Dr. Garcia\", \"Prof. Rodriguez\", \"Dr. Lee\", \n",
    "    \"Prof. Patel\", \"Dr. Chen\", \"Prof. Kim\", \n",
    "    \"Dr. Martinez\", \"Prof. Wilson\", \"Dr. Taylor\"\n",
    "]\n",
    "\n",
    "notes = [\n",
    "    \"Advanced Course\", \"Introductory Level\", \n",
    "    \"Requires Prior Knowledge\", \"Practical Session\", \n",
    "    \"Research Oriented\", \"Theoretical Framework\", \n",
    "    \"Group Project Required\", \"Comprehensive Exam\", \n",
    "    \"Elective Course\", \"Core Curriculum\",\n",
    "    \"Lab Intensive\", \"Seminar Based\", \n",
    "    \"Independent Study\", \"Field Research\"\n",
    "]\n",
    "\n",
    "# Generate 100 rows of simulated data\n",
    "num_rows = 100\n",
    "data = {\n",
    "    'Subject': random.choices(subjects, k=num_rows),\n",
    "    'Exam Time': [random.randint(1, 6) for _ in range(num_rows)],\n",
    "    'Classroom': random.choices(classrooms, k=num_rows),\n",
    "    'Teacher': random.choices(teachers, k=num_rows),\n",
    "    'Notes': random.choices(notes, k=num_rows)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(r'/home/ubuntu/mnt2/wxy/Ako_GPT/data/exam_info.csv', index=False)\n",
    "\n",
    "print(df.head(10))\n",
    "print(f\"\\nTotal rows generated: {len(df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_etuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
